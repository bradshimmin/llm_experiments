{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic notebook for use in testing Together.ai models\n",
    "[Reference](https://docs.together.ai/docs/python-library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "# Install Together library\n",
    "%pip install -q --upgrade together\n",
    "\n",
    "# Import modules\n",
    "import together\n",
    "import os\n",
    "\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3\n"
     ]
    }
   ],
   "source": [
    "# Check API key\n",
    "print(os.environ['TOGETHER_API_KEY'][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64 models available\n"
     ]
    }
   ],
   "source": [
    "# Check available models\n",
    "model_list = together.Models.list()\n",
    "\n",
    "print(f\"There are {len(model_list)} models available\")\n",
    "\n",
    "model_names = [model_dict[\"name\"] for model_dict in model_list]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EleutherAI/gpt-j-6b',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'EleutherAI/pythia-12b-v0',\n",
       " 'EleutherAI/pythia-1b-v0',\n",
       " 'EleutherAI/pythia-2.8b-v0',\n",
       " 'EleutherAI/pythia-6.9b',\n",
       " 'HuggingFaceH4/starchat-alpha',\n",
       " 'NousResearch/Nous-Hermes-13b',\n",
       " 'NousResearch/Nous-Hermes-Llama2-13b',\n",
       " 'NumbersStation/nsql-6B',\n",
       " 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5',\n",
       " 'OpenAssistant/stablelm-7b-sft-v7-epoch-3',\n",
       " 'bigcode/starcoder',\n",
       " 'databricks/dolly-v2-12b',\n",
       " 'databricks/dolly-v2-3b',\n",
       " 'databricks/dolly-v2-7b',\n",
       " 'google/flan-t5-xl',\n",
       " 'huggyllama/llama-13b',\n",
       " 'huggyllama/llama-30b',\n",
       " 'huggyllama/llama-65b',\n",
       " 'huggyllama/llama-7b',\n",
       " 'lmsys/fastchat-t5-3b-v1.0',\n",
       " 'lmsys/vicuna-13b-v1.3',\n",
       " 'lmsys/vicuna-7b-v1.3',\n",
       " 'prompthero/openjourney',\n",
       " 'runwayml/stable-diffusion-v1-5',\n",
       " 'stabilityai/stable-diffusion-2-1',\n",
       " 'stabilityai/stable-diffusion-xl-base-1.0',\n",
       " 'stabilityai/stablelm-base-alpha-3b',\n",
       " 'stabilityai/stablelm-base-alpha-7b',\n",
       " 'tatsu-lab/alpaca-7b-wdiff',\n",
       " 'timdettmers/guanaco-7b',\n",
       " 'togethercomputer/GPT-JT-6B-v1',\n",
       " 'togethercomputer/GPT-JT-Moderation-6B',\n",
       " 'togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
       " 'togethercomputer/Koala-13B',\n",
       " 'togethercomputer/Koala-7B',\n",
       " 'togethercomputer/LLaMA-2-7B-32K',\n",
       " 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
       " 'togethercomputer/Pythia-Chat-Base-7B-v0.16',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Base',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Chat',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
       " 'togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
       " 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
       " 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
       " 'togethercomputer/codegen2-16B',\n",
       " 'togethercomputer/codegen2-7B',\n",
       " 'togethercomputer/falcon-40b-instruct',\n",
       " 'togethercomputer/falcon-40b',\n",
       " 'togethercomputer/falcon-7b-instruct',\n",
       " 'togethercomputer/falcon-7b',\n",
       " 'togethercomputer/llama-2-13b-chat',\n",
       " 'togethercomputer/llama-2-13b',\n",
       " 'togethercomputer/llama-2-70b-chat',\n",
       " 'togethercomputer/llama-2-70b',\n",
       " 'togethercomputer/llama-2-7b-chat',\n",
       " 'togethercomputer/llama-2-7b',\n",
       " 'togethercomputer/mpt-30b-chat',\n",
       " 'togethercomputer/mpt-30b',\n",
       " 'togethercomputer/mpt-7b-chat',\n",
       " 'togethercomputer/mpt-7b-instruct',\n",
       " 'togethercomputer/mpt-7b',\n",
       " 'togethercomputer/replit-code-v1-3b']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List available models\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': '00c58e3a9a0767409a0c8f30f7631a90b03874b1fc012cc655fdeca8ff1a9920'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start up our target model\n",
    "together.Models.start(\"togethercomputer/llama-2-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tatsu-lab/alpaca-7b-wdiff': False,\n",
       " 'togethercomputer/llama-2-7b': False,\n",
       " 'togethercomputer/mpt-30b-chat': False,\n",
       " 'togethercomputer/llama-2-70b-chat': False,\n",
       " 'togethercomputer/llama-2-7b-chat': False,\n",
       " '/huggyllama/llama-7b': False,\n",
       " '/togethercomputer/LLaMA-2-7B-32K': False,\n",
       " '/togethercomputer/llama-2-7b-chat': False,\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Chat': False,\n",
       " 'togethercomputer/mpt-7b': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show running model\n",
    "together.Models.instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dandy\n",
      "I'm a Yankee Doodle Dandy,\n",
      "A real live nephew of my Uncle Sam.\n",
      "Born on the Fourth of July in the land of the free.\n",
      "And I'm mighty proud of that glorious old flag\n",
      "That stands for the red man and white,\n",
      "The home of the free and the brave.\n",
      "Yankee Doodle went to town riding on a pony;\n",
      "Stuck a feather in his\n"
     ]
    }
   ],
   "source": [
    "# Run basic completion query\n",
    "\n",
    "my_model_name = \"togethercomputer/llama-2-7b\"\n",
    "my_prompt = \"I'm a yankee doodle\"\n",
    "\n",
    "output = together.Complete.create(\n",
    "    prompt = my_prompt,\n",
    "    model = my_model_name,\n",
    "    max_tokens = 100,\n",
    "    temperature = 0.6,\n",
    "    top_k = 90,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.1,\n",
    "    stop = [\"</s>\"]\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(output[\"output\"][\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", London is one of the most visited cities in Europe. It has a rich history and culture that attracts tourists from all over the world. The cityâ€™s architecture is unique and diverse with many different styles represented throughout its streets.\n",
      "London is also home to some of the best museums in Europe including Tate Modern, British Museum, National Gallery and Victoria & Albert Museum which offer visitors an opportunity to explore artwork dating back centuries as well as modern pieces created by contemporary artists\n"
     ]
    }
   ],
   "source": [
    "my_prompt = \"The capital of England\"\n",
    "\n",
    "output = together.Complete.create(\n",
    "    prompt = my_prompt,\n",
    "    model = my_model_name,\n",
    "    max_tokens = 100,\n",
    "    temperature = 0.6,\n",
    "    top_k = 90,\n",
    "    top_p = 0.8,\n",
    "    repetition_penalty = 1.1,\n",
    "    stop = [\"</s>\"]\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(output[\"output\"][\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shut down model instance\n",
    "together.Models.stop(\"/togethercomputer/LLaMA-2-7B-32K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
